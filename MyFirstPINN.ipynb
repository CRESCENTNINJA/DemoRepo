{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730ca217-38dd-4852-b55a-24c95374b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f64f059-e129-4048-a192-36fc15fc7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_solution(d, w0, t):\n",
    "    \"def the exact soln analytic for the above problem\"\n",
    "    assert d<w0\n",
    "    w = np.sqrt(w0**2 - d**2)\n",
    "    phi = np.arctan(-d/w)\n",
    "    A=1/(2*np.cos(phi))\n",
    "    cos = torch.cos(phi + w*t)\n",
    "    exep =torch.exp(-d*t)\n",
    "    u= exp*2*A*cos\n",
    "    return u\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    \"Defines a standard fully connected network in pytorch:\"\n",
    "\n",
    "def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "    super().__init__()\n",
    "    activation = nn.Tanh\n",
    "    self.fcs = nn.Sequential (*[\n",
    "                    nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                    acrivation()])\n",
    "    self.fch = nn.Sequential(*[\n",
    "                    nn.Sequential(*[\n",
    "                        nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                        activation()]) for _ in range(N_LAYERS - 1)])\n",
    "\n",
    "    self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "\n",
    "def forward(self, x):\n",
    "    x= self.fcs(x)\n",
    "    x=self.fch(x)\n",
    "    x=self.fce(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38c61e-97af-4c3e-91e3-c71601db4629",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "#define a neural network to train\n",
    "pinn = FCN(1, 1, 32, 3)\n",
    "\n",
    "\n",
    "#define boundary points, for the boundary loss\n",
    "t_boundary = torch.tensor(0.).view(-1,1).requires_grad_(True)\n",
    "\n",
    "\n",
    "\n",
    "#define training points over the entire domain, for the physics loss\n",
    "t_physics = torch.linspace(0,1, 30).view(-1, 1).requires_grad_(True)\n",
    "\n",
    "#Training the PINN\n",
    "d, w0= 2, 20\n",
    "mu, k= 2*d, w0**2\n",
    "t_test= torch.linspace(0,1, 300).view(-1,1)\n",
    "u_exact = exact_solution(d, w0, t_test)\n",
    "optimiser = torch.optim.Adam(pinn.parameters(), lr= 1e-3)\n",
    "\n",
    "for i in range(15001):\n",
    "    optimiser.zero_grad()\n",
    "    #compute each term of the PNIN loss funcitno above:\n",
    "    #using the following hyper parameters;\n",
    "    lambda1, lambda2=1e-1, 1e-4\n",
    "\n",
    "\n",
    "#compute boundary loss\n",
    "#compute physics loss\n",
    "#backpropagate joint loss, take optimiser step\n",
    "\n",
    "    u = pinn(t_boundary) #(1,1)\n",
    "    loss1= (torch.squeeze(u) -1)**2\n",
    "\n",
    "    dudt = torch.autograd.grad(u, t_boundary, torch.ones_like(u), create_graph= True)[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
